{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6a8f90",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a5500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tynnie/PSS-TA/master/data/comment_tag_all_groups.csv')\n",
    "df = df.replace({'無關對美立場': -99, \n",
    "           '有關-親美1': 1,\n",
    "           '有關-仇美-1': -1,\n",
    "           '有關-中立0': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4283443b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>token_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[榨菜, 又名, 腦殘聰, ！, 他, 說, 美國, 貿易, 必勝, ，, 全世界, 只有,...</td>\n",
       "      <td>[榨菜, 又名, 腦殘聰, 說, 美國, 貿易, 必勝, 全世界, 一人, 說, 美國, 貿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[@, 李北芷, 。,  , 沒錯,  , …, 蔡是, 來, 分裂, 我們, 中國人,  ...</td>\n",
       "      <td>[李北芷, 沒錯, 蔡是, 分裂, 中國人, 亞洲, 人, 知道, 亞洲, 地區, 華人團,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[拿, 金正恩, 換郭文貴,  , 他, 自己, 幾斤, 幾, 兩, 不, 清楚,  , 你...</td>\n",
       "      <td>[金正恩, 換郭文貴, 幾斤, 兩, 清楚, 還不, 清楚, 郭文貴, 哪天會, 爆料, 出...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[美國人, 戒告, 他們, 的, 廠, 商說, ：, 小心, 大陸用, 監控, 監視, 你,...</td>\n",
       "      <td>[美國人, 戒告, 廠, 商說, 小心, 大陸用, 監控, 監視, 美國廠, 商問, 政府,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[中國間諜, ？, 根本就是, 榨菜, 綠黨, 寫, 的, 腳本, ，, 配合, 美澳, 主...</td>\n",
       "      <td>[中國間諜, 根本就是, 榨菜, 綠黨, 寫, 腳本, 配合, 美澳, 主子, 反共, 遏華...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[笑, 死, ~, ~, ~,  ,  , 郭台銘, 做, 甚麼, 都, 是, 對, 的, ...</td>\n",
       "      <td>[笑, 死, 郭台銘, 做, 川普親, 自面, 試好, 棒棒, 糖香龍, 說, 韓總, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[見川普, 又, 怎樣, ?,  , 美國還, 不是, 把, 台灣當, 棋子, ,,  , ...</td>\n",
       "      <td>[見川普, 美國還, 台灣當, 棋子, 個頭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[郭現, 在, 是, 參選人, ,, 還, 不是, 提名, 人, ,, 況且, 川, 普會永...</td>\n",
       "      <td>[郭現, 參選人, 提名, 人, 川, 普會永遠, 當美國, 總統, 台美會, 郭, 建交]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[現在川, 普變, 正面人物, 了, ？, 受美國, 人面, 試層級, 決定, 台灣, 總統...</td>\n",
       "      <td>[現在川, 普變, 正面人物, 受美國, 人面, 試層級, 決定, 台灣, 總統候, 選人,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[Samrock,  , Erian,  , 美國, 、, 日本, 照樣, 死刑, 你, 看...</td>\n",
       "      <td>[Samrock, Erian, 美國, 日本, 照樣, 死刑, 歐盟, 放個, 屁, 聞聞]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0                     榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，   -1.0   \n",
       "5     @李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...   -1.0   \n",
       "6     拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...   -1.0   \n",
       "7     美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...   -1.0   \n",
       "14    中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...   -1.0   \n",
       "...                                                 ...    ...   \n",
       "1473  笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...   -1.0   \n",
       "1483                     見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了   -1.0   \n",
       "1487            郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?   -1.0   \n",
       "1488  現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...   -1.0   \n",
       "1495             Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？   -1.0   \n",
       "\n",
       "                                             token_text  \\\n",
       "0     [榨菜, 又名, 腦殘聰, ！, 他, 說, 美國, 貿易, 必勝, ，, 全世界, 只有,...   \n",
       "5     [@, 李北芷, 。,  , 沒錯,  , …, 蔡是, 來, 分裂, 我們, 中國人,  ...   \n",
       "6     [拿, 金正恩, 換郭文貴,  , 他, 自己, 幾斤, 幾, 兩, 不, 清楚,  , 你...   \n",
       "7     [美國人, 戒告, 他們, 的, 廠, 商說, ：, 小心, 大陸用, 監控, 監視, 你,...   \n",
       "14    [中國間諜, ？, 根本就是, 榨菜, 綠黨, 寫, 的, 腳本, ，, 配合, 美澳, 主...   \n",
       "...                                                 ...   \n",
       "1473  [笑, 死, ~, ~, ~,  ,  , 郭台銘, 做, 甚麼, 都, 是, 對, 的, ...   \n",
       "1483  [見川普, 又, 怎樣, ?,  , 美國還, 不是, 把, 台灣當, 棋子, ,,  , ...   \n",
       "1487  [郭現, 在, 是, 參選人, ,, 還, 不是, 提名, 人, ,, 況且, 川, 普會永...   \n",
       "1488  [現在川, 普變, 正面人物, 了, ？, 受美國, 人面, 試層級, 決定, 台灣, 總統...   \n",
       "1495  [Samrock,  , Erian,  , 美國, 、, 日本, 照樣, 死刑, 你, 看...   \n",
       "\n",
       "                                                cleaned  \n",
       "0     [榨菜, 又名, 腦殘聰, 說, 美國, 貿易, 必勝, 全世界, 一人, 說, 美國, 貿...  \n",
       "5     [李北芷, 沒錯, 蔡是, 分裂, 中國人, 亞洲, 人, 知道, 亞洲, 地區, 華人團,...  \n",
       "6     [金正恩, 換郭文貴, 幾斤, 兩, 清楚, 還不, 清楚, 郭文貴, 哪天會, 爆料, 出...  \n",
       "7     [美國人, 戒告, 廠, 商說, 小心, 大陸用, 監控, 監視, 美國廠, 商問, 政府,...  \n",
       "14    [中國間諜, 根本就是, 榨菜, 綠黨, 寫, 腳本, 配合, 美澳, 主子, 反共, 遏華...  \n",
       "...                                                 ...  \n",
       "1473  [笑, 死, 郭台銘, 做, 川普親, 自面, 試好, 棒棒, 糖香龍, 說, 韓總, 40...  \n",
       "1483                            [見川普, 美國還, 台灣當, 棋子, 個頭]  \n",
       "1487     [郭現, 參選人, 提名, 人, 川, 普會永遠, 當美國, 總統, 台美會, 郭, 建交]  \n",
       "1488  [現在川, 普變, 正面人物, 受美國, 人面, 試層級, 決定, 台灣, 總統候, 選人,...  \n",
       "1495    [Samrock, Erian, 美國, 日本, 照樣, 死刑, 歐盟, 放個, 屁, 聞聞]  \n",
       "\n",
       "[486 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c8667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-99.0: 512, -1.0: 385, 0.0: 266, 1.0: 36})\n",
      "Counter({-99.0: 672, -1.0: 447, 0.0: 333, 1.0: 47})\n",
      "Counter({-99.0: 548, -1.0: 429, 0.0: 166, 1.0: 57})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pprint\n",
    "pprint.pprint(Counter(df.student_1.dropna()))\n",
    "pprint.pprint(Counter(df.student_2.dropna()))\n",
    "pprint.pprint(Counter(df.student_3.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85db684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 704, 0: 690, 1: 106})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = []\n",
    "for s1, s2, s3, in zip(df.student_1, df.student_2, df.student_3):\n",
    "    if s1==1 or s2==1 or s3==1:\n",
    "        label.append(1)\n",
    "    elif(any([s1==-1, s2==-1, s3==-1])):\n",
    "        label.append(-1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "df['label'] = label\n",
    "Counter(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd88fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['student_3']\n",
    "df = df.loc[df['label'].isin([-1, 1])]\n",
    "df = df.iloc[:, [3, 8]].set_axis(['text', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd2bf7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0                     榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，   -1.0\n",
       "5     @李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...   -1.0\n",
       "6     拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...   -1.0\n",
       "7     美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...   -1.0\n",
       "14    中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...   -1.0\n",
       "...                                                 ...    ...\n",
       "1473  笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...   -1.0\n",
       "1483                     見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了   -1.0\n",
       "1487            郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?   -1.0\n",
       "1488  現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...   -1.0\n",
       "1495             Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？   -1.0\n",
       "\n",
       "[486 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fba469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/61/5bvzqdmn7455dm96br7vs9jw0000gn/T/jieba.cache\n",
      "Loading model cost 0.795 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[榨菜, 又名, 腦殘聰, ！, 他, 說, 美國, 貿易, 必勝, ，, 全世界, 只有,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[@, 李北芷, 。,  , 沒錯,  , …, 蔡是, 來, 分裂, 我們, 中國人,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[拿, 金正恩, 換郭文貴,  , 他, 自己, 幾斤, 幾, 兩, 不, 清楚,  , 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[美國人, 戒告, 他們, 的, 廠, 商說, ：, 小心, 大陸用, 監控, 監視, 你,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[中國間諜, ？, 根本就是, 榨菜, 綠黨, 寫, 的, 腳本, ，, 配合, 美澳, 主...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[笑, 死, ~, ~, ~,  ,  , 郭台銘, 做, 甚麼, 都, 是, 對, 的, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[見川普, 又, 怎樣, ?,  , 美國還, 不是, 把, 台灣當, 棋子, ,,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[郭現, 在, 是, 參選人, ,, 還, 不是, 提名, 人, ,, 況且, 川, 普會永...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[現在川, 普變, 正面人物, 了, ？, 受美國, 人面, 試層級, 決定, 台灣, 總統...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[Samrock,  , Erian,  , 美國, 、, 日本, 照樣, 死刑, 你, 看...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0                     榨菜又名腦殘聰！他說美國貿易必勝，全世界只有他一人說美國貿易必勝，   -1.0   \n",
       "5     @李北芷。 沒錯 …蔡是來分裂我們中國人 亞洲人 … 你知道如果我們亞洲地區華人團結起來 ，...   -1.0   \n",
       "6     拿金正恩換郭文貴 他自己幾斤幾兩不清楚 你們還不清楚嘛 郭文貴哪天會不會爆料出美國拿郭文貴跟...   -1.0   \n",
       "7     美國人戒告他們的廠商說：小心大陸用監控監視你們~~  美國廠商問政府：你怎麼知道我們要跟大陸...   -1.0   \n",
       "14    中國間諜？根本就是榨菜綠黨寫的腳本，配合美澳主子的反共遏華毀華國際大戲，通過一個大陸外逃詐騙...   -1.0   \n",
       "...                                                 ...    ...   \n",
       "1473  笑死~~~  郭台銘做甚麼都是對的! 川普親自面試好棒棒!!  糖香龍 說韓總拿4000萬 ...   -1.0   \n",
       "1483                     見川普又怎樣? 美國還不是把台灣當棋子, 只是多了個頭像罷了   -1.0   \n",
       "1487            郭現在是參選人,還不是提名人,況且川普會永遠當美國的總統嗎?台美會因郭建交嗎?   -1.0   \n",
       "1488  現在川普變正面人物了？受美國人面試層級決定台灣總統候選人高度了？唐趙不是之前不齒赴美面試嗎？...   -1.0   \n",
       "1495             Samrock Erian 美國、日本照樣死刑你看，歐盟放個屁都要去聞聞嗎？   -1.0   \n",
       "\n",
       "                                             token_text  \n",
       "0     [榨菜, 又名, 腦殘聰, ！, 他, 說, 美國, 貿易, 必勝, ，, 全世界, 只有,...  \n",
       "5     [@, 李北芷, 。,  , 沒錯,  , …, 蔡是, 來, 分裂, 我們, 中國人,  ...  \n",
       "6     [拿, 金正恩, 換郭文貴,  , 他, 自己, 幾斤, 幾, 兩, 不, 清楚,  , 你...  \n",
       "7     [美國人, 戒告, 他們, 的, 廠, 商說, ：, 小心, 大陸用, 監控, 監視, 你,...  \n",
       "14    [中國間諜, ？, 根本就是, 榨菜, 綠黨, 寫, 的, 腳本, ，, 配合, 美澳, 主...  \n",
       "...                                                 ...  \n",
       "1473  [笑, 死, ~, ~, ~,  ,  , 郭台銘, 做, 甚麼, 都, 是, 對, 的, ...  \n",
       "1483  [見川普, 又, 怎樣, ?,  , 美國還, 不是, 把, 台灣當, 棋子, ,,  , ...  \n",
       "1487  [郭現, 在, 是, 參選人, ,, 還, 不是, 提名, 人, ,, 況且, 川, 普會永...  \n",
       "1488  [現在川, 普變, 正面人物, 了, ？, 受美國, 人面, 試層級, 決定, 台灣, 總統...  \n",
       "1495  [Samrock,  , Erian,  , 美國, 、, 日本, 照樣, 死刑, 你, 看...  \n",
       "\n",
       "[486 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "df['token_text'] = df['text'].apply(lambda x:list(jieba.cut(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b36baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/stopwords_zh-tw.txt\", encoding=\"utf-8\") as fin:\n",
    "    stopwords = fin.read().split(\"\\n\")[1:]\n",
    "\n",
    "\n",
    "import unicodedata # for removing Chinese puctuation\n",
    "def remove_punc_by_unicode(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word != \" \" and not unicodedata.category(word[0]).startswith('P'):\n",
    "            out.append(word)\n",
    "    return out\n",
    "def remove_stopWords(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            out.append(word)\n",
    "    return out\n",
    "df['cleaned'] = df['token_text'].apply(remove_punc_by_unicode).apply(remove_stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc6edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1.0: 429, 1.0: 57})\n",
      "['榨菜 又名 腦殘聰 說 美國 貿易 必勝 全世界 一人 說 美國 貿易 必勝', '李北芷 沒錯 蔡是 分裂 中國人 亞洲 人 知道 亞洲 地區 華人團 結起 人口 比美 國 日本 還要', '金正恩 換郭文貴 幾斤 兩 清楚 還不 清楚 郭文貴 哪天會 爆料 出美國 郭文貴 中國 換習 近平 真的 腦子 缺氧 人才 會信', '美國人 戒告 廠 商說 小心 大陸用 監控 監視 美國廠 商問 政府 知道 大陸 廠商 合作 美國 政府 電郵 裏 看到', '中國間諜 根本就是 榨菜 綠黨 寫 腳本 配合 美澳 主子 反共 遏華毀 華國際 大戲 一個 大陸 外逃 詐騙 犯之口 搞 出口 轉內銷 台島 詐騙 黨 大陸詐 騙 犯 一家人 一家 親 爲 美國 人作 看門 狗 爲 榮']\n"
     ]
    }
   ],
   "source": [
    "documents = [\" \".join(doc) for doc in df['cleaned']]\n",
    "y = df['label']\n",
    "print(Counter(y))\n",
    "print(documents[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1149849",
   "metadata": {},
   "source": [
    "# Grid + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0488502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa6586",
   "metadata": {},
   "source": [
    "## Pipeline design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c504fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe= Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e82dba",
   "metadata": {},
   "source": [
    "## Grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7588834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_df': [0.01, 0.05, 0.1, 0.2, 1.0],\n",
    "    'tfidf__token_pattern': [r\"(?u)\\b\\w+\\b\", r\"(?u)\\b\\w\\w+\\b\"],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__penalty': ('l1', 'l2', 'none'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ca543",
   "metadata": {},
   "source": [
    "## Grid Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33942306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirlong/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.8827267  0.8827267  0.8827267  0.8827267\n",
      " 0.8827267  0.8827267  0.88687145 0.88687145 0.88274774 0.88274774\n",
      " 0.88891227 0.88891227 0.88891227 0.89097412 0.88891227 0.88893331\n",
      " 0.88070692 0.88070692 0.88685041 0.88891227 0.88893331 0.88480959\n",
      " 0.88891227 0.88068588 0.88072796 0.87043972 0.88891227 0.8827267\n",
      " 0.88893331 0.87868714 0.88891227 0.8827267  0.88072796 0.87043972\n",
      " 0.88891227 0.88066484 0.88893331 0.87868714 0.88891227 0.87454239\n",
      " 0.88072796 0.86431727 0.88891227 0.88066484 0.88893331 0.87664633]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__penalty': ('l1', 'l2', 'none'),\n",
       "                         'tfidf__max_df': [0.01, 0.05, 0.1, 0.2, 1.0],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfidf__token_pattern': ['(?u)\\\\b\\\\w+\\\\b',\n",
       "                                                  '(?u)\\\\b\\\\w\\\\w+\\\\b'],\n",
       "                         'tfidf__use_idf': (True, False)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose = 3)\n",
    "grid.fit(documents, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad591320",
   "metadata": {},
   "source": [
    "## Show best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "117376df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8909741216074059\n",
      "Params: \n",
      "clf__penalty: 'none'\n",
      "tfidf__max_df: 0.01\n",
      "tfidf__ngram_range: (1, 2)\n",
      "tfidf__token_pattern: '(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
      "tfidf__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(\"Params: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b8003ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_tfidf__max_df</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__token_pattern</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(?u)\\b\\w+\\b</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(?u)\\b\\w+\\b</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(?u)\\b\\w+\\b</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>False</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.864317</td>\n",
       "      <td>0.034062</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(?u)\\b\\w+\\b</td>\n",
       "      <td>True</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.888912</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(?u)\\b\\w+\\b</td>\n",
       "      <td>False</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.880665</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>True</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.888933</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(?u)\\b\\w\\w+\\b</td>\n",
       "      <td>False</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.876646</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_clf__penalty param_tfidf__max_df param_tfidf__ngram_range  \\\n",
       "0                   l1                0.01                   (1, 1)   \n",
       "1                   l1                0.01                   (1, 1)   \n",
       "2                   l1                0.01                   (1, 1)   \n",
       "3                   l1                0.01                   (1, 1)   \n",
       "4                   l1                0.01                   (1, 2)   \n",
       "..                 ...                 ...                      ...   \n",
       "115               none                 1.0                   (1, 1)   \n",
       "116               none                 1.0                   (1, 2)   \n",
       "117               none                 1.0                   (1, 2)   \n",
       "118               none                 1.0                   (1, 2)   \n",
       "119               none                 1.0                   (1, 2)   \n",
       "\n",
       "    param_tfidf__token_pattern param_tfidf__use_idf  split0_test_score  \\\n",
       "0                  (?u)\\b\\w+\\b                 True                NaN   \n",
       "1                  (?u)\\b\\w+\\b                False                NaN   \n",
       "2                (?u)\\b\\w\\w+\\b                 True                NaN   \n",
       "3                (?u)\\b\\w\\w+\\b                False                NaN   \n",
       "4                  (?u)\\b\\w+\\b                 True                NaN   \n",
       "..                         ...                  ...                ...   \n",
       "115              (?u)\\b\\w\\w+\\b                False           0.806122   \n",
       "116                (?u)\\b\\w+\\b                 True           0.877551   \n",
       "117                (?u)\\b\\w+\\b                False           0.877551   \n",
       "118              (?u)\\b\\w\\w+\\b                 True           0.867347   \n",
       "119              (?u)\\b\\w\\w+\\b                False           0.826531   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                  NaN                NaN                NaN   \n",
       "1                  NaN                NaN                NaN   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "115           0.886598           0.896907           0.886598   \n",
       "116           0.896907           0.907216           0.886598   \n",
       "117           0.886598           0.896907           0.865979   \n",
       "118           0.896907           0.917526           0.886598   \n",
       "119           0.876289           0.917526           0.896907   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                  NaN              NaN             NaN              120  \n",
       "1                  NaN              NaN             NaN               95  \n",
       "2                  NaN              NaN             NaN               94  \n",
       "3                  NaN              NaN             NaN               93  \n",
       "4                  NaN              NaN             NaN               92  \n",
       "..                 ...              ...             ...              ...  \n",
       "115           0.845361         0.864317        0.034062               80  \n",
       "116           0.876289         0.888912        0.011771                7  \n",
       "117           0.876289         0.880665        0.010426               72  \n",
       "118           0.876289         0.888933        0.017392                2  \n",
       "119           0.865979         0.876646        0.030683               76  \n",
       "\n",
       "[120 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_).filter(regex='(param_.*)|(.*test_score)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa467e1",
   "metadata": {},
   "source": [
    "# Pipeline Final run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469dbeb8",
   "metadata": {},
   "source": [
    "## train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d156ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf4021",
   "metadata": {},
   "source": [
    "## Definine classifier according to GridSearch result and pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ced28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf = True,\n",
    "#                         token_pattern = r\"(?u)\\\\b\\\\w+\\\\b\",\n",
    "                        ngram_range=(1, 2),\n",
    "                        max_df=1\n",
    "                       )\n",
    "\n",
    "pipe= Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "#     ('chi2', SelectKBest(chi2, k=5000)),\n",
    "#     ('clf', RandomForestClassifier(n_estimators=10))\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8a89d",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0af1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835616438356164\n",
      "[[129   0]\n",
      " [ 17   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.88      1.00      0.94       129\n",
      "         1.0       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.88       146\n",
      "   macro avg       0.44      0.50      0.47       146\n",
      "weighted avg       0.78      0.88      0.83       146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirlong/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jirlong/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jirlong/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "cr = classification_report(y_test, predicted)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c1475",
   "metadata": {},
   "source": [
    "# Deal with imbalanced data\n",
    "\n",
    "## with imblearn\n",
    "- How to deal with imbalanced data https://towardsdatascience.com/how-to-deal-with-imbalanced-data-in-python-f9b71aba53eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53fedf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc2611",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3714c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After oversampling:  Counter({-1.0: 300, 1.0: 300})\n",
      "After undersampling:  Counter({-1.0: 40, 1.0: 40})\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from collections import Counter\n",
    "\n",
    "over_sampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(numpy.array(X_train).reshape(-1,1), y_train)\n",
    "print(\"After oversampling: \", Counter(y_train_over))\n",
    "\n",
    "under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(numpy.array(X_train).reshape(-1,1), y_train)\n",
    "print(\"After undersampling: \", Counter(y_train_under))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1998a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_train_sm, y_train_sm = sm.fit_resample(numpy.array(X_train).reshape(-1,1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a06fc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over_sampler = [doc[0] for doc in X_train_over.tolist()]\n",
    "X_train_under_sampler = [doc[0] for doc in X_train_under.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4ca2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_tfidf(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    tfidf = TfidfVectorizer(use_idf = False,\n",
    "#                             token_pattern = r\"(?u)\\b\\w+\\b\",\n",
    "                            ngram_range=(1, 1),\n",
    "                            max_df=0.5\n",
    "                           )\n",
    "\n",
    "    pipe= Pipeline([\n",
    "        ('tfidf', tfidf),\n",
    "#         ('chi2', SelectKBest(chi2, k=5000)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=10))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    predicted = pipe.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "    cm = confusion_matrix(y_test, predicted)\n",
    "    cr = classification_report(y_test, predicted)\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    print(accuracy)\n",
    "    print(cm)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f2a1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8972602739726028\n",
      "[[126   3]\n",
      " [ 12   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.91      0.98      0.94       129\n",
      "         1.0       0.62      0.29      0.40        17\n",
      "\n",
      "    accuracy                           0.90       146\n",
      "   macro avg       0.77      0.64      0.67       146\n",
      "weighted avg       0.88      0.90      0.88       146\n",
      "\n",
      "0.4863013698630137\n",
      "[[59 70]\n",
      " [ 5 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.46      0.61       129\n",
      "         1.0       0.15      0.71      0.24        17\n",
      "\n",
      "    accuracy                           0.49       146\n",
      "   macro avg       0.53      0.58      0.43       146\n",
      "weighted avg       0.83      0.49      0.57       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_tfidf(X_train_over_sampler, X_test, y_train_over, y_test)\n",
    "best_tfidf(X_train_under_sampler, X_test, y_train_under, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
