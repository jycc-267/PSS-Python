{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0de9f49",
   "metadata": {},
   "source": [
    "# Detecting hot posts by classification\n",
    "\n",
    "1. 目的：我們收到社群輿論資料共一萬多筆貼文（posts），想要從裡面建立一個分類模型來偵測什麼樣的貼文會「爆」（假設某則post有超過100則回文（comments），以PTT的語彙來說，就是爆了）。\n",
    "2. 依變項（Dependent）：依變項為每則posts的回文數，把100則回文以上的文章視為1，把少於100則回文的視為0（切勿不可將回文數當成自變項，如果這麼做就會被扣很多分數）。但你也可以嘗試以不一樣的方式去切割，但要注意盡可能保持1/0兩個分類貼文數的平衡。\n",
    "3. 自變項（Independent）：至少要以貼文內容作為自變項，但可以用貼文標題、貼文作者、貼文時間來訓練。除此之外，我們還提供了前10則回文，說不定影響一則貼文會不會爆的主要因素是前十則回文。你可以自己決定要不要把回文丟下去當自變項。本作業的要求只有要求要用貼文當自變項。\n",
    "4. 參考版本：助教用simpletransformer寫了個[版本](https://colab.research.google.com/drive/1YQZNlzH_mo7_Q3XU8X2sIpkhrQZWVYar?usp=sharing)給各位參考，但作為示範助教僅使用了貼文內容作為特徵來訓練模型、也使用了較少的資料集（在時間上做了點切割）。你可以使用全部的貼文來預測，或者可以嘗試加入每則貼文的前10則回文來預測。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f30f5e-7d53-4f25-b0d2-389bd7453f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0df87",
   "metadata": {},
   "source": [
    "# 讀取資料\n",
    "1. 貼文資料https://github.com/p4css/PSS/blob/master/data/ptt_post.pickle\n",
    "2. 回文資料https://github.com/p4css/PSS/blob/master/data/ptt_comment10.pickle \n",
    "貼文與相對應的回文資料均以plink作為key，可以用pandas的merge將兩個資料集給連結起來做訓練。但要怎麼把前十則的回文化為貼文特徵，要想想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d573b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"../data/ptt_post.pickle\")\n",
    "df2 = pd.read_pickle(\"../data/ptt_comment10.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653467f5-c0ea-4326-85b1-c6ccad6a9576",
   "metadata": {},
   "source": [
    "## 資料標記"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b400ca-5142-4a47-abde-164d67630fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6274\n",
      "0    5875\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ipaddr</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>Ncomment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119222660....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...</td>\n",
       "      <td>Muroi (I Honestly Love You)</td>\n",
       "      <td>Re: (問題)華航空難留言</td>\n",
       "      <td>Mon Jun 20 07:28:27 2005</td>\n",
       "      <td>138.130.212.179</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119233779....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...</td>\n",
       "      <td>JCC (JCC                    )</td>\n",
       "      <td>Re: 有沒有明天會更好的八卦</td>\n",
       "      <td>Mon Jun 20 10:21:53 2005</td>\n",
       "      <td>211.20.78.69</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119257927....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>我聽到的是： 記者問張跟路有沒有要結婚 家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就回說 ...</td>\n",
       "      <td>vancie (我不正 我很歪 )</td>\n",
       "      <td>Re: [新聞] 張震月的八卦有嗎？</td>\n",
       "      <td>Mon Jun 20 17:07:13 2005</td>\n",
       "      <td>※ 發信站: 批踢踢實業坊(ptt.cc)</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119258686....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...</td>\n",
       "      <td>J1 (andy)</td>\n",
       "      <td>Re: [政商] 請問桌伯元的八卦?</td>\n",
       "      <td>Mon Jun 20 17:18:14 2005</td>\n",
       "      <td>220.141.159.23</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119271499....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...</td>\n",
       "      <td>ilcd (南特 巴黎 白朗峰!!! )</td>\n",
       "      <td>Re: 有沒有米其淋的美食還是什麼評鑑八卦</td>\n",
       "      <td>Mon Jun 20 20:53:24 2005</td>\n",
       "      <td>218.167.152.79</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink      board  \\\n",
       "0  https://www.ptt.cc/bbs/Gossiping/M.1119222660....  Gossiping   \n",
       "1  https://www.ptt.cc/bbs/Gossiping/M.1119233779....  Gossiping   \n",
       "2  https://www.ptt.cc/bbs/Gossiping/M.1119257927....  Gossiping   \n",
       "3  https://www.ptt.cc/bbs/Gossiping/M.1119258686....  Gossiping   \n",
       "4  https://www.ptt.cc/bbs/Gossiping/M.1119271499....  Gossiping   \n",
       "\n",
       "                                            pcontent  \\\n",
       "0  看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...   \n",
       "1  那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...   \n",
       "2  我聽到的是： 記者問張跟路有沒有要結婚 家人有沒有在催。。。巴拉巴拉的 張覺得很煩，就回說 ...   \n",
       "3  太想被M,得到P幣 再八卦一下 桌伯元先生真的不是台大法學碩士 它是 國立台灣大學法律系學士...   \n",
       "4  米其林是家輪胎公司 米其林兄弟發行了一本只送不賣的輪胎手冊 讓所有自動車 自行車 機車的車主...   \n",
       "\n",
       "                          poster                 ptitle  \\\n",
       "0    Muroi (I Honestly Love You)         Re: (問題)華航空難留言   \n",
       "1  JCC (JCC                    )        Re: 有沒有明天會更好的八卦   \n",
       "2              vancie (我不正 我很歪 )     Re: [新聞] 張震月的八卦有嗎？   \n",
       "3                      J1 (andy)     Re: [政商] 請問桌伯元的八卦?   \n",
       "4           ilcd (南特 巴黎 白朗峰!!! )  Re: 有沒有米其淋的美食還是什麼評鑑八卦   \n",
       "\n",
       "                      ptime                 ipaddr  ip.len  Ncomment labels  \n",
       "0  Mon Jun 20 07:28:27 2005        138.130.212.179       1       944      1  \n",
       "1  Mon Jun 20 10:21:53 2005           211.20.78.69       1       350      1  \n",
       "2  Mon Jun 20 17:07:13 2005  ※ 發信站: 批踢踢實業坊(ptt.cc)       0       156      1  \n",
       "3  Mon Jun 20 17:18:14 2005         220.141.159.23       1       160      1  \n",
       "4  Mon Jun 20 20:53:24 2005         218.167.152.79       1       153      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['pcontent'] = df1.pcontent.apply(lambda x: re.sub(r'\\n+', '\\n', x).strip())\n",
    "df1['pcontent'] = df1.pcontent.apply(lambda x: x.replace('\\u3000', ''))\n",
    "df1['pcontent'] = df1.pcontent.apply(lambda x: x.replace('\\n', ' ').replace(r'(www|http:|https:)+[^\\s]+[\\w]', ' ').strip())\n",
    "df1['labels'] = pd.cut(df1.Ncomment, bins=[-np.inf, 100, np.inf], labels=[0, 1])\n",
    "print(df1.labels.value_counts())\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc78764-1a3f-4fed-b854-26b32f87fabd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 資料清理: 內文、標題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635ea6d7-7cc3-479d-bd04-8477a8f114c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.203 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 內文斷詞\n",
    "df1['token_content'] = df1['pcontent'].apply(lambda x: list(jieba.cut(x)))\n",
    "\n",
    "# 移除標點符號\n",
    "def remove_punc_by_unicode(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word != \" \" and not unicodedata.category(word[0]).startswith('P'):\n",
    "            out.append(word)\n",
    "    return out\n",
    "\n",
    "df1['cleaned_content'] = df1['token_content'].apply(remove_punc_by_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c08896-a849-40ce-8956-03b2db89d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標題斷詞\n",
    "df1['token_title'] = df1['ptitle'].astype('str').apply(lambda x: list(jieba.cut(x)))\n",
    "\n",
    "# 移除標點符號\n",
    "df1['cleaned_title'] = df1['token_title'].apply(remove_punc_by_unicode)\n",
    "\n",
    "# 區別標題與內文\n",
    "def distinguisher(words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        out.append('Title' + word)\n",
    "    return out\n",
    "df1['cleaned_title'] = df1['cleaned_title'].apply(distinguisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d6c61b-8fea-42b5-b464-6e42798dd147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ipaddr</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>Ncomment</th>\n",
       "      <th>labels</th>\n",
       "      <th>token_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>token_title</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119222660....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...</td>\n",
       "      <td>Muroi (I Honestly Love You)</td>\n",
       "      <td>Re: (問題)華航空難留言</td>\n",
       "      <td>Mon Jun 20 07:28:27 2005</td>\n",
       "      <td>138.130.212.179</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "      <td>[看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...</td>\n",
       "      <td>[看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...</td>\n",
       "      <td>[Re, :,  , (, 問題, ), 華, 航空, 難, 留言]</td>\n",
       "      <td>[TitleRe, Title問題, Title華, Title航空, Title難, Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1119233779....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...</td>\n",
       "      <td>JCC (JCC                    )</td>\n",
       "      <td>Re: 有沒有明天會更好的八卦</td>\n",
       "      <td>Mon Jun 20 10:21:53 2005</td>\n",
       "      <td>211.20.78.69</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...</td>\n",
       "      <td>[那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...</td>\n",
       "      <td>[Re, :,  , 有, 沒, 有, 明天, 會, 更好, 的, 八卦]</td>\n",
       "      <td>[TitleRe, Title有, Title沒, Title有, Title明天, Tit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink      board  \\\n",
       "0  https://www.ptt.cc/bbs/Gossiping/M.1119222660....  Gossiping   \n",
       "1  https://www.ptt.cc/bbs/Gossiping/M.1119233779....  Gossiping   \n",
       "\n",
       "                                            pcontent  \\\n",
       "0  看到這推文,忍不住要寫一個飛機沒油的例子  很久之前在讀者文摘上看到,現憑印象寫文,有錯請指...   \n",
       "1  那不是為了反盜版 那是為了捐錢給消基會 當年美國唱了 WE ARE THE WORLD之後 ...   \n",
       "\n",
       "                          poster           ptitle                     ptime  \\\n",
       "0    Muroi (I Honestly Love You)   Re: (問題)華航空難留言  Mon Jun 20 07:28:27 2005   \n",
       "1  JCC (JCC                    )  Re: 有沒有明天會更好的八卦  Mon Jun 20 10:21:53 2005   \n",
       "\n",
       "            ipaddr  ip.len  Ncomment labels  \\\n",
       "0  138.130.212.179       1       944      1   \n",
       "1     211.20.78.69       1       350      1   \n",
       "\n",
       "                                       token_content  \\\n",
       "0  [看到, 這推文, ,, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子,  , ...   \n",
       "1  [那, 不是, 為, 了, 反盜, 版,  , 那, 是, 為, 了, 捐, 錢給, 消基會...   \n",
       "\n",
       "                                     cleaned_content  \\\n",
       "0  [看到, 這推文, 忍不住, 要, 寫, 一個, 飛機, 沒油, 的, 例子, 很, 久, ...   \n",
       "1  [那, 不是, 為, 了, 反盜, 版, 那, 是, 為, 了, 捐, 錢給, 消基會, 當...   \n",
       "\n",
       "                             token_title  \\\n",
       "0     [Re, :,  , (, 問題, ), 華, 航空, 難, 留言]   \n",
       "1  [Re, :,  , 有, 沒, 有, 明天, 會, 更好, 的, 八卦]   \n",
       "\n",
       "                                       cleaned_title  \n",
       "0  [TitleRe, Title問題, Title華, Title航空, Title難, Ti...  \n",
       "1  [TitleRe, Title有, Title沒, Title有, Title明天, Tit...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d36a42-ad83-4302-a209-4ef9c028b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [\" \".join(doc) for doc in df1['cleaned_content']]\n",
    "titles = [\" \".join(doc) for doc in df1['cleaned_title']]\n",
    "\n",
    "document = []\n",
    "for i in range(len(contents)):\n",
    "    document.append(titles[i]+\" \"+contents[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4912bd-e762-46db-907a-f2e9222e53b4",
   "metadata": {},
   "source": [
    "## 建立變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c34fec9-bb8f-406c-8fb4-397bfe5025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf\n",
    "from sklearn.feature_selection import SelectKBest, chi2 # tf-idf with chi-squared\n",
    "\n",
    "# Feature Selection: embedding\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import scipy\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca493776-95ad-4084-b8ab-01c29278ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = document\n",
    "Y = df1['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4102684-82e4-4293-bb6a-c075b5f72251",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/stopwords_zh-tw.txt\", encoding=\"utf-8\") as fin:\n",
    "    stopwords = fin.read().split(\"\\n\")[1:]\n",
    "\n",
    "X_tfidf = TfidfVectorizer(max_df = 1.0, ngram_range = (1, 2), max_features = 20000, stop_words = stopwords).fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53343ad4-9a1d-4b20-9f53-bf7e9dc8194b",
   "metadata": {},
   "source": [
    "# Parameter Selection with Grid and Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf9a2b-6cd1-4f7e-894c-6b49e18b90c4",
   "metadata": {},
   "source": [
    "## Pipeline Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6638d2e-ed84-48bb-8c02-f2d55f1b0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([('chi2', SelectKBest(score_func=chi2)), \n",
    "                  ('logistic', LogisticRegression())])\n",
    "\n",
    "pipe2 = Pipeline([('chi2', SelectKBest(score_func=chi2)), \n",
    "                  ('bayes', GaussianNB())])\n",
    "\n",
    "pipe3 = Pipeline([('chi2', SelectKBest(score_func=chi2)), \n",
    "                  ('tree', GradientBoostingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f076770-7116-4f50-ab8d-90b9fdbca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = {'chi2__k': [1000, 2000, 5000, 10000, 20000], \n",
    "               'logistic__solver': ['newton-cg', 'sag', 'lbfgs'], \n",
    "               'logistic__penalty': ('l2', 'none')}\n",
    "\n",
    "parameters2 = {'chi2__k': [1000, 2000, 5000, 10000, 20000]}\n",
    "\n",
    "parameters3 = {'chi2__k': [1000, 2000, 5000, 10000, 20000], \n",
    "               'tree__n_estimators': [100, 200, 500], \n",
    "               'tree__learning_rate': [0.05, 0.1, 0.2], \n",
    "               'tree__max_features': [\"sqrt\", \"log2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d30d5c",
   "metadata": {},
   "source": [
    "# 切割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "468fafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_tfidf.toarray(), Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04208486-7a9a-463f-b191-7749ed2e3a9c",
   "metadata": {},
   "source": [
    "## 模型測試"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21731160-4b46-4f4a-8805-af552687014b",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9810ad32-de6b-421b-bc5f-2dfaf5c12e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('chi2',\n",
       "                                        SelectKBest(score_func=<function chi2 at 0x000001A10F8B4DC0>)),\n",
       "                                       ('logistic', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'chi2__k': [1000, 2000, 5000, 10000, 20000],\n",
       "                         'logistic__penalty': ('l2', 'none'),\n",
       "                         'logistic__solver': ['newton-cg', 'sag', 'lbfgs']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe1, parameters1, cv=5, n_jobs=-1, verbose = 3).fit(X_train, Y_train)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7a1b527-cdc0-4cde-8614-285257b4bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892074558218348\n",
      "Params: \n",
      "chi2__k: 20000\n",
      "logistic__penalty: 'l2'\n",
      "logistic__solver: 'newton-cg'\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(\"Params: \")\n",
    "for param_name in sorted(parameters1.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dac55-272e-4602-a03b-85a3ff03c93c",
   "metadata": {},
   "source": [
    "### Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95500cb2-e5b7-4f3f-a070-58eb8cb7e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('chi2',\n",
       "                                        SelectKBest(score_func=<function chi2 at 0x000001A10F8B4DC0>)),\n",
       "                                       ('bayes', GaussianNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'chi2__k': [1000, 2000, 5000, 10000, 20000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = GridSearchCV(pipe2, parameters2, cv=5, n_jobs=-1, verbose = 3).fit(X_train, Y_train)\n",
    "grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77168a03-35b2-43a4-ae8f-49dfad806dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6067705501953868\n",
      "Params: \n",
      "chi2__k: 10000\n"
     ]
    }
   ],
   "source": [
    "print(grid2.best_score_)\n",
    "print(\"Params: \")\n",
    "for param_name in sorted(parameters2.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid2.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d54d90-0863-437f-9d93-b7e01e4c5bcf",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c803e845-1edf-42c1-8e26-deba7fd1b67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('chi2',\n",
       "                                        SelectKBest(score_func=<function chi2 at 0x000001A10F8B4DC0>)),\n",
       "                                       ('tree', GradientBoostingClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'chi2__k': [1000, 2000, 5000, 10000, 20000],\n",
       "                         'tree__learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'tree__max_features': ['sqrt', 'log2'],\n",
       "                         'tree__n_estimators': [100, 200, 500]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3 = GridSearchCV(pipe3, parameters3, cv=5, n_jobs=-1, verbose = 3).fit(X_train, Y_train)\n",
    "grid3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a83c148-0144-4505-8e8f-0aa06b78988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6924990835840508\n",
      "Params: \n",
      "chi2__k: 2000\n",
      "tree__learning_rate: 0.05\n",
      "tree__max_features: 'sqrt'\n",
      "tree__n_estimators: 500\n"
     ]
    }
   ],
   "source": [
    "print(grid3.best_score_)\n",
    "print(\"Params: \")\n",
    "for param_name in sorted(parameters3.keys()):\n",
    "    print(\"%s: %r\" % (param_name, grid3.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde61c6b",
   "metadata": {},
   "source": [
    "# 訓練模型: final run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a76ab37-9de8-41b0-a1d8-9cdc2e159c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "def train_model(classifier, train, train_label, test, test_label):\n",
    "    classifier.fit(train, train_label)\n",
    "    pred_label = classifier.predict(test)\n",
    "    print(confusion_matrix(test_label, pred_label))\n",
    "    print(classification_report(test_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36209f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1225  530]\n",
      " [ 544 1346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70      1755\n",
      "           1       0.72      0.71      0.71      1890\n",
      "\n",
      "    accuracy                           0.71      3645\n",
      "   macro avg       0.70      0.71      0.71      3645\n",
      "weighted avg       0.71      0.71      0.71      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "X_logistic = SelectKBest(score_func=chi2, k=20000).fit_transform(X_tfidf, Y)\n",
    "X_logistic_train, X_logistic_test, Y_logistic_train, Y_logistic_test = train_test_split(X_logistic.toarray(), Y, test_size=0.3)\n",
    "train_model(LogisticRegression(penalty = 'l2', solver = 'newton-cg'), X_logistic_train, Y_logistic_train, X_logistic_test, Y_logistic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0daf6623-86e8-4531-ab37-df7bffe090a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1253  505]\n",
      " [ 619 1268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1758\n",
      "           1       0.72      0.67      0.69      1887\n",
      "\n",
      "    accuracy                           0.69      3645\n",
      "   macro avg       0.69      0.69      0.69      3645\n",
      "weighted avg       0.69      0.69      0.69      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bayes\n",
    "X_bayes = SelectKBest(score_func=chi2, k=10000).fit_transform(X_tfidf, Y)\n",
    "X_bayes_train, X_bayes_test, Y_bayes_train, Y_bayes_test = train_test_split(X_bayes.toarray(), Y, test_size=0.3)\n",
    "train_model(GaussianNB(), X_bayes_train, Y_bayes_train, X_bayes_test, Y_bayes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16ccabdf-ad51-43e4-bfad-a8466490fb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1220  564]\n",
      " [ 534 1327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      1784\n",
      "           1       0.70      0.71      0.71      1861\n",
      "\n",
      "    accuracy                           0.70      3645\n",
      "   macro avg       0.70      0.70      0.70      3645\n",
      "weighted avg       0.70      0.70      0.70      3645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoosting\n",
    "X_boosting = SelectKBest(score_func=chi2, k=2000).fit_transform(X_tfidf, Y)\n",
    "X_boosting_train, X_boosting_test, Y_boosting_train, Y_boosting_test = train_test_split(X_boosting.toarray(), Y, test_size=0.3)\n",
    "train_model(GradientBoostingClassifier(learning_rate = 0.05, n_estimators = 500, max_features = 'sqrt'), X_boosting_train, Y_boosting_train, X_boosting_test, Y_boosting_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f1bf",
   "metadata": {},
   "source": [
    "# 預測結果\n",
    "預測結果應包含`classification_report`並應用`from mlxtend.plotting import plot_confusion_matrix`繪製confision_matrix的視覺化結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5475fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fced7387-0959-446f-b97d-620586ab2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier, train, train_label, test, test_label):\n",
    "    classifier.fit(train, train_label)\n",
    "    pred_label = classifier.predict(test)\n",
    "    print(classification_report(test_label, pred_label))\n",
    "    return confusion_matrix(test_label, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aec667e2-d285-4e35-9795-e2aa92eb7908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 + Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70      1755\n",
      "           1       0.72      0.71      0.71      1890\n",
      "\n",
      "    accuracy                           0.71      3645\n",
      "   macro avg       0.70      0.71      0.71      3645\n",
      "weighted avg       0.71      0.71      0.71      3645\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "chi2 + Bayes Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1758\n",
      "           1       0.72      0.67      0.69      1887\n",
      "\n",
      "    accuracy                           0.69      3645\n",
      "   macro avg       0.69      0.69      0.69      3645\n",
      "weighted avg       0.69      0.69      0.69      3645\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "chi2 + GradientBoosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69      1784\n",
      "           1       0.70      0.71      0.71      1861\n",
      "\n",
      "    accuracy                           0.70      3645\n",
      "   macro avg       0.70      0.70      0.70      3645\n",
      "weighted avg       0.70      0.70      0.70      3645\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"chi2 + Logistic Regression\")\n",
    "cm1 = evaluation(LogisticRegression(penalty = 'l2', solver = 'newton-cg'), X_logistic_train, Y_logistic_train, X_logistic_test, Y_logistic_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm1)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"chi2 + Bayes Classifier\")\n",
    "cm2 = evaluation(GaussianNB(), X_bayes_train, Y_bayes_train, X_bayes_test, Y_bayes_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm2)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"chi2 + GradientBoosting\")\n",
    "cm3 = evaluation(GradientBoostingClassifier(learning_rate = 0.05, n_estimators = 500, max_features = 'sqrt'), X_boosting_train, Y_boosting_train, X_boosting_test, Y_boosting_test)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm3)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40528918",
   "metadata": {},
   "source": [
    "# 分析預測結果\n",
    "Q1. 你把什麼樣的特徵丟進去當自變項（最基本要有貼文，但你還可以丟貼文的發文者、時間、標題、前十則回文內容、回文作者）？\n",
    "> 將標題、內文當作自變項，並將兩這併入同一個document中，在標題的文字中加上\"Title\"區別標題文字與內文文字。\n",
    "\n",
    "Q2. 你認為這個模型的分類能力好嗎？請說明模型訓練結果。\n",
    "> 我測的三個模型f-1 score都在7成上下(因為預測八卦爆不爆的效益不高，我認為7成雖不算高但可以接受)，recall rate以及precision rate也都在1-2%內。三個模型比較起來的話，是貝氏分類器的效果最差，Logistic Regression的效果跟GradientBoosting差不多。而Logistic Regression確實也在binary classification上表現較好(雖然‘newton-cg’較其他solver更專注處理multiclass的問題)。差別較大的地方在於三個模型適合的chi-square feature數，分別是羅吉斯20000、貝氏10000、決策數2000。\n",
    "\n",
    "Q3. 你認為ptt貼文內容適合拿來做訓練資料嗎？為什麼？\n",
    "> 不太適合，最初不使用tfidf轉換成sparse matrix的時候約有將近22萬個column。縱使之後配合chi-square去篩選適合的feature數量，每筆留言也可能因為八卦版的主題內容過於雜亂而讓每篇文章沒有代表性。\n",
    "\n",
    "Q4. 若加入其他參考特徵後，模型有什麼樣的改變呢（如果你沒做的話就不用回答）？\n",
    "> 我假設鄉民有受到標題影響的判斷的傾向，因此僅加入標題做為附加的參考特徵(一方面也是因為方便處理)。我認為這對於訓練結果會有改善，但可能不太顯著。原因在於標題跟內文都是文字資料，轉成tfidf後都是在算詞頻權重。加入發文時間可能會是個更強的參考特徵。\n",
    "\n",
    "Q5. 如果你在Daily Scrum上要回報這個任務，請用100字以上、200字以內精簡且精準地回報模型訓練結果。\n",
    "> 我對ptt八卦版的貼文內容進行爆的可能性預測，以文章標題跟內容作為自變項，目標使用tfidf跟chi-square對自變項進行篩選。在模型訓練上，將訓練資料與測試資料按七三的比例拆分，分別跑了效果較好的Logistic Regression、GradientBoosting，以及效果較差的Bayes Classifier。其中，預測是爆的文章中實際上也有70%是爆;真的是爆的文章中也有70%左右的比例真的被找出來。\n",
    "> 將停詞移除、加入作者、發文時間應該能進一步提升模型的準確度，但該如何區別作者這個文字變項也要思考。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
